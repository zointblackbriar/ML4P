install.packages(MASS)
install.packages("MASS")
data <- Boston
data <- Boston
data <- Boston
data <- Boston
data <- Boston
data <- Boston
data <- Boston
data <- Boston
data(Boston)
library(MASS)
data <- Boston
View(data)
data <- Boston
View(data)
apply(data, 2, function(x) sum(is.na(x)))
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
test$medv
test <- data[-index, ]
lm.fit <- glm(med~., data=train)
summary(lm.fit)
pr.lm <- predict(lm.fit, test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2) / nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
q()
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
install.packages("ggplot")
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
install.packages("ggplot")
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
install.packages("ggplot2")
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/LinearRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/nyc-taxi-data/analysis/2017_update/analysis_2017.R')
help('%>%')
help '??%>%'
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
y <- mtcars$hp
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
f <- function(x)
x^2 + x +  1
print(f(2))
return (x^2 + x +  1)
}
print(f(2))
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
f <- function(x){
return (x^2 + x +  1)
}
print(f(2))
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
print(sample)
print(sample.first)
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Basic Example.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/RidgeRegression.R')
?dim()
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
# least-squares cost function
cost <- function(X, y, theta) {
# computes the cost of using theta as the parameter for linear regression
# to fit the data points in X and y
sum((X %*% theta - y)^2)/(2 * length(y))
}
delta <- function(x, y, theta) {
error <- (x %*% theta - y)
delta <- t(x) %*% error/length(y)
return((delta))
}
# gradient descent update algorithm
gradescent <- function(x, y, theta, alpha) {
#theta = gradescent(X, y, alpha)
theta <- theta - alpha * delta(x, y, theta)
return(theta)
}
dependentValue <- my_data$HARDNESSP1
independentValues <- my_data[1:8]
fix(dependentValue)
# fix(dependentValue)
# fix(independentValues)
independentValues <- my_data[1:8]
fitted_model <- lm( dependentValue ~ independentValues, data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
print(fitted_model)
delta <- function(x, y, theta) {
error <- (x %*% theta - y)
delta <- t(x) %*% error/length(y)
return((delta))
}
# gradient descent update algorithm
gradescent <- function(x, y, theta, alpha) {
#theta = gradescent(X, y, alpha)
theta <- theta - alpha * delta(x, y, theta)
return(theta)
}
dependentValue <- my_data$HARDNESSP1
#predictor linear model set
currentDirectory <- getwd()
setwd("C:\\Users\\zoint\\Desktop\\AllFiles\\Projeler\\R_Projects")
directoryChanged <- getwd()
my_data <- read_excel("Autoform_1000.xlsx")
#Gradient Descent with Linear Regression
#Choose a learning rate for gradient descent
if(!require(magrittr)) {
install.packages("magrittr"); require(magrittr)
}
if(!require(dplyr)) {
install.packages("dplyr"); require(dplyr)
}
if(!require(readxl)) {
install.packages("readxl"); require(readxl)
}
# least-squares cost function
cost <- function(X, y, theta) {
# computes the cost of using theta as the parameter for linear regression
# to fit the data points in X and y
sum((X %*% theta - y)^2)/(2 * length(y))
}
delta <- function(x, y, theta) {
error <- (x %*% theta - y)
delta <- t(x) %*% error/length(y)
return((delta))
}
# gradient descent update algorithm
gradescent <- function(x, y, theta, alpha) {
#theta = gradescent(X, y, alpha)
theta <- theta - alpha * delta(x, y, theta)
return(theta)
}
#predictor linear model set
currentDirectory <- getwd()
setwd("C:\\Users\\zoint\\Desktop\\AllFiles\\Projeler\\R_Projects")
directoryChanged <- getwd()
my_data <- read_excel("Autoform_1000.xlsx")
dependentValue <- my_data$HARDNESSP1
independentValues <- my_data[1:8]
fitted_model <- lm( dependentValue ~ independentValues, data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
print(fitted_model)
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
fitted_model <- lm( HARDNESSP1 ~ independentValues, data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
print(fitted_model)
theta_lm<-coef(fitted_model); #least squares parameter estimates
print(theta_lm) #print the parameters
print(paste0("coefficient of regression: ", summary( fitted_model )$r.squared))   # R ^ 2 coefficient of regression
print(paste0("mean squared error: ",  mean(residuals( fitted_model )^2)))
num_iters <- 100
independentValues <- cbind(1, matrix(independentValues))  # column of 1 was added for intercept coefficient
cost_history <- double(num_iters)  # to keep the cost history
theta_history <- list(num_iters)
theta_grad <- matrix(c(0, 0), nrow = 2)  # Initialize the parameters
alpha = 0.05  # set learning rate
for (i in 1:num_iters) {
theta_grad <- gradescent(independentValues, dependentValue, theta_grad, alpha)
cost_history[i] <- cost(dependentValue, independentValues, theta_grad)
theta_history[[i]] <- theta_grad
}
plot(dependentValue ~ independentValues)  #scatter plot of data (var and response)
plot(HARDNESSP1 ~ .)  #scatter plot of data (var and response)
plot(HARDNESSP1 ~ independentValues)  #scatter plot of data (var and response)
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
print(fitted_model)
theta_lm<-coef(fitted_model); #least squares parameter estimates
print(theta_lm) #print the parameters
print(paste0("coefficient of regression: ", summary( fitted_model )$r.squared))   # R ^ 2 coefficient of regression
print(paste0("mean squared error: ",  mean(residuals( fitted_model )^2)))
num_iters <- 100
independentValues <- cbind(1, matrix(independentValues))  # column of 1 was added for intercept coefficient
cost_history <- double(num_iters)  # to keep the cost history
theta_history <- list(num_iters)
theta_grad <- matrix(c(0, 0), nrow = 2)  # Initialize the parameters
alpha = 0.05  # set learning rate
for (i in 1:num_iters) {
theta_grad <- gradescent(independentValues, dependentValue, theta_grad, alpha)
cost_history[i] <- cost(dependentValue, independentValues, theta_grad)
theta_history[[i]] <- theta_grad
}
theta_grad <- gradescent(independentValues, dependentValue, theta_grad, alpha)
cost_history[i] <- cost(dependentValue, independentValues, theta_grad)
#theta = gradescent(X, y, alpha)
theta <- theta - (alpha * delta(x, y, theta))
#theta = gradescent(X, y, alpha)
theta <- theta - alpha * delta(x, y, theta)
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
# least-squares cost function
cost <- function(X, y, theta) {
# computes the cost of using theta as the parameter for linear regression
# to fit the data points in X and y
sum((X %*% theta - y)^2)/(2 * length(y))
}
delta <- function(x, y, theta) {
error <- (x %*% theta - y)
delta <- t(x) %*% error/length(y)
return((delta))
}
# gradient descent update algorithm
gradescent <- function(x, y, theta, alpha) {
#theta = gradescent(X, y, alpha)
theta <- theta - (alpha * delta(x, y, theta))
return(theta)
}
#predictor linear model set
currentDirectory <- getwd()
setwd("C:\\Users\\zoint\\Desktop\\AllFiles\\Projeler\\R_Projects")
directoryChanged <- getwd()
my_data <- read_excel("Autoform_1000.xlsx")
dependentValue <- my_data$HARDNESSP1
independentValues <- my_data[1:8]
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
#
# dependentValue <- my_data$HARDNESSP1
#
# dependentValue <- my_data$HARDNESSP1
#
# dependentValue <- my_data$HARDNESSP1
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
print(fitted_model)
theta_lm<-coef(fitted_model); #least squares parameter estimates
print(theta_lm) #print the parameters
print(paste0("coefficient of regression: ", summary( fitted_model )$r.squared))   # R ^ 2 coefficient of regression
num_iters <- 100
print(paste0("mean squared error: ",  mean(residuals( fitted_model )^2)))
independentValues <- cbind(1, matrix(independentValues))  # column of 1 was added for intercept coefficient
cost_history <- double(num_iters)  # to keep the cost history
theta_history <- list(num_iters)
theta_grad <- matrix(c(0, 0), nrow = 2)  # Initialize the parameters
alpha = 0.05  # set learning rate
for (i in 1:num_iters) {
theta_grad <- gradescent(independentValues, dependentValue, theta_grad, alpha)
cost_history[i] <- cost(dependentValue, independentValues, theta_grad)
theta_history[[i]] <- theta_grad
}
#theta = gradescent(X, y, alpha)
theta <- theta - (alpha * delta(x, y, theta))
return(theta)
theta_grad <- gradescent(independentValues, dependentValue, theta_grad, alpha)
#theta = gradescent(X, y, alpha)
theta <- theta - (alpha * delta(as.matrix(x), as.matrix(y), theta))
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
independentValues <- my_data[1:8]
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(x,y, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
my_data <- read_excel("Autoform_1000.xlsx")
#
dependentValue <- my_data$HARDNESSP1
independentValues <- my_data[1:8]
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(dependentValue,independentValues, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
# print(fitted_model)
plot(HARDNESSP1,independentValues, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
#
dependentValue <- my_data[1:8]$HARDNESSP1
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
#
dependentValue <- my_data[,9]
print(dependentValue)
fitted_model <- lm( dependentValue ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(HARDNESSP1,independentValues, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
# print(fitted_model)
plot(dependentValue,independentValues, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
abline(res, col='blue')
abline(fitted_model, col='blue')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
#
dependentValue <- my_data[,9]
print(dependentValue)
independentValues <- my_data[1:8]
# fix(dependentValue)
fix(independentValues)
independentValues <- my_data[1:7]
# fix(dependentValue)
fix(independentValues)
independentValues <- my_data[1:8]
# fix(dependentValue)
fix(independentValues)
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(dependentValue,independentValues, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
abline(fitted_model, col='blue')
#
dependentValue <- data.frame(my_data[,9])
print(dependentValue)
independentValues <- my_data[1:8]
# fix(dependentValue)
fix(independentValues)
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(dependentValue,independentValues, col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
abline(fitted_model, col='blue')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
# print(fitted_model)
plot(dependentValue,independentValues, main='Linear regression by gradient descent')
# print(fitted_model)
plot(independentValues,dependentValue, main='Linear regression by gradient descent')
# fix(independentValues)
# fix(independentValues)
# fix(independentValues)
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(independentValues,dependentValue,col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
abline(fitted_model, col='blue')
# print(fitted_model)
plot(HARDNESSP1,dependentValue,col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
source('C:/Users/zoint/Desktop/AllFiles/Projeler/R_Projects/Gradient Descent with Linear Regression.R')
independentValues <- my_data[1:8]
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(dependentValue,dependentValue,col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
dependentValue <- my_data[,9]
print(dependentValue)
independentValues <- my_data[1:8]
fitted_model <- lm( HARDNESSP1 ~ ., data=my_data[1:9]) # y=theta0+theta1*x+epsilon(error)
# print(fitted_model)
plot(independentValues,dependentValue,col=rgb(0.2,0.4,0.6,0.4), main='Linear regression by gradient descent')
abline(fitted_model, col='blue')
